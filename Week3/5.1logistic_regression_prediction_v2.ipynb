{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
    "</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Objective</h2><ul><li> How to create a logistic regression object with the nn.Sequential model.</li></ul> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<p>In this lab, we will cover logistic regression using PyTorch.</p>\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#Log\">Logistic Function</a></li>\n",
    "    <li><a href=\"#Seq\">Build a Logistic Regression Using nn.Sequential</a></li>\n",
    "    <li><a href=\"#Model\">Build Custom Modules</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>15 min</strong></p>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparation</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the following libraries:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we need for this lab\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random seed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fee1018aab0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "\n",
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Log\">Logistic Function</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor ranging from -100 to 100:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor:  tensor([[-100.0000],\n",
      "        [ -99.9000],\n",
      "        [ -99.8000],\n",
      "        ...,\n",
      "        [  99.7000],\n",
      "        [  99.8000],\n",
      "        [  99.9000]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.arange(-100, 100, 0.1).view(-1, 1)\n",
    "print(\"The tensor: \", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sigmoid object: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sigmoid object\n",
    "\n",
    "sig = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the element-wise function Sigmoid with the object:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sigmoid object to calculate the \n",
    "\n",
    "yhat = sig(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'yhat')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z.numpy(), yhat.numpy())\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('yhat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the element-wise Sigmoid from the function module and plot the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feddfc4cc90>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = torch.sigmoid(z)\n",
    "plt.plot(z.numpy(), yhat.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Seq\">Build a Logistic Regression with <code>nn.Sequential</code></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 1x1 tensor where x represents one data sample with one dimension, and 2x1 tensor X represents two data samples of one dimension:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  tensor([[1.]])\n",
      "X =  tensor([[  1.],\n",
      "        [100.]])\n"
     ]
    }
   ],
   "source": [
    "# Create x and X tensor\n",
    "\n",
    "x = torch.tensor([[1.0]])\n",
    "X = torch.tensor([[1.0], [100]])\n",
    "print('x = ', x)\n",
    "print('X = ', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a logistic regression object with the <code>nn.Sequential</code> model with a one-dimensional input:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sequential function to create model\n",
    "\n",
    "model = nn.Sequential(nn.Linear(1, 1), nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object is represented in the following diagram: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.1.1_logistic_regression_block_diagram.png\" width = 800, align = \"center\" alt=\"logistic regression block diagram\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the parameters are randomly initialized. You can view them the following ways:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(model.parameters()):\n",
      "  [Parameter containing:\n",
      "tensor([[0.2294]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2380], requires_grad=True)]\n",
      "\n",
      "model.state_dict():\n",
      "  OrderedDict([('0.weight', tensor([[0.2294]])), ('0.bias', tensor([-0.2380]))])\n"
     ]
    }
   ],
   "source": [
    "# Print the parameters\n",
    "\n",
    "print(\"list(model.parameters()):\\n \", list(model.parameters()))\n",
    "print(\"\\nmodel.state_dict():\\n \", model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction with one sample:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction:  tensor([[0.4979]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# The prediction for x\n",
    "\n",
    "yhat = model(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the object with tensor <code>X</code> performed the following operation <b>(code values may not be the same as the diagrams value  depending on the version of PyTorch) </b>:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.1.1_logistic_functio_example%20.png\" width=\"400\" alt=\"Logistic Example\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction with multiple samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4979],\n",
       "        [1.0000]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The prediction for X\n",
    "\n",
    "yhat = model(X)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the object performed the following operation: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 1x2 tensor where x represents one data sample with one dimension, and 2x3 tensor X represents one data sample of two dimensions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  tensor([[1., 1.]])\n",
      "X =  tensor([[1., 1.],\n",
      "        [1., 2.],\n",
      "        [1., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# Create and print samples\n",
    "\n",
    "x = torch.tensor([[1.0, 1.0]])\n",
    "X = torch.tensor([[1.0, 1.0], [1.0, 2.0], [1.0, 3.0]])\n",
    "print('x = ', x)\n",
    "print('X = ', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a logistic regression object with the <code>nn.Sequential</code> model with a two-dimensional input: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model using nn.sequential()\n",
    "\n",
    "model = nn.Sequential(nn.Linear(2, 1), nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object will apply the Sigmoid function to the output of the linear function as shown in the following diagram:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.1.1logistic_output.png\" width=\"800\" alt=\"The structure of nn.sequential\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the parameters are randomly initialized. You can view them the following ways:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(model.parameters()):\n",
      "  [Parameter containing:\n",
      "tensor([[ 0.1939, -0.0361]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3021], requires_grad=True)]\n",
      "\n",
      "model.state_dict():\n",
      "  OrderedDict([('0.weight', tensor([[ 0.1939, -0.0361]])), ('0.bias', tensor([0.3021]))])\n"
     ]
    }
   ],
   "source": [
    "# Print the parameters\n",
    "\n",
    "print(\"list(model.parameters()):\\n \", list(model.parameters()))\n",
    "print(\"\\nmodel.state_dict():\\n \", model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction with one sample:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction:  tensor([[0.6130]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction of x\n",
    "\n",
    "yhat = model(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operation is represented in the following diagram:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.3.1.logisticwithouptut.png\" width=\"500\" alt=\"Sequential Example\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction with multiple samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction:  tensor([[0.6130],\n",
      "        [0.6044],\n",
      "        [0.5957]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# The prediction of X\n",
    "\n",
    "yhat = model(X)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operation is represented in the following diagram: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.1.1_logistic_with_outputs2.png\" width=\"800\" alt=\"Sequential Example\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Model\">Build Custom Modules</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will build a custom Module or class. The model or object function is identical to using <code>nn.Sequential</code>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a logistic regression custom module:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic_regression custom class\n",
    "\n",
    "class logistic_regression(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, n_inputs):\n",
    "        super(logistic_regression, self).__init__()\n",
    "        self.linear = nn.Linear(n_inputs, 1)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        yhat = torch.sigmoid(self.linear(x))\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 1x1 tensor where x represents one data sample with one dimension, and 3x1 tensor where $X$ represents one data sample of one dimension:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  tensor([[1.]])\n",
      "X =  tensor([[-100.],\n",
      "        [   0.],\n",
      "        [ 100.]])\n"
     ]
    }
   ],
   "source": [
    "# Create x and X tensor\n",
    "\n",
    "x = torch.tensor([[1.0]])\n",
    "X = torch.tensor([[-100], [0], [100.0]])\n",
    "print('x = ', x)\n",
    "print('X = ', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model to predict one dimension: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression model\n",
    "\n",
    "model = logistic_regression(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the parameters are randomly initialized. You can view them the following ways:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(model.parameters()):\n",
      "  [Parameter containing:\n",
      "tensor([[0.2381]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1149], requires_grad=True)]\n",
      "\n",
      "model.state_dict():\n",
      "  OrderedDict([('linear.weight', tensor([[0.2381]])), ('linear.bias', tensor([-0.1149]))])\n"
     ]
    }
   ],
   "source": [
    "# Print parameters \n",
    "\n",
    "print(\"list(model.parameters()):\\n \", list(model.parameters()))\n",
    "print(\"\\nmodel.state_dict():\\n \", model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction with one sample:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result: \n",
      " tensor([[0.5307]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction of x\n",
    "\n",
    "yhat = model(x)\n",
    "print(\"The prediction result: \\n\", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction with multiple samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result: \n",
      " tensor([[4.0805e-11],\n",
      "        [4.7130e-01],\n",
      "        [1.0000e+00]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction of X\n",
    "\n",
    "yhat = model(X)\n",
    "print(\"The prediction result: \\n\", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a logistic regression object with a function with two inputs: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logistic regression model\n",
    "\n",
    "model = logistic_regression(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 1x2 tensor where x represents one data sample with one dimension, and 3x2 tensor X represents one data sample of one dimension:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  tensor([[1., 2.]])\n",
      "X =  tensor([[ 100., -100.],\n",
      "        [   0.,    0.],\n",
      "        [-100.,  100.]])\n"
     ]
    }
   ],
   "source": [
    "# Create x and X tensor\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0]])\n",
    "X = torch.tensor([[100, -100], [0.0, 0.0], [-100, 100]])\n",
    "print('x = ', x)\n",
    "print('X = ', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction with one sample:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result: \n",
      " tensor([[0.2943]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction of x\n",
    "\n",
    "yhat = model(x)\n",
    "print(\"The prediction result: \\n\", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction with multiple samples: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result: \n",
      " tensor([[7.7529e-33],\n",
      "        [3.4841e-01],\n",
      "        [1.0000e+00]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction of X\n",
    "\n",
    "yhat = model(X)\n",
    "print(\"The prediction result: \\n\", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practice</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make your own model <code>my_model</code> as applying linear regression first and then logistic regression using <code>nn.Sequential()</code>. Print out your prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction:  tensor([0.2231], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Practice: Make your model and make the prediction\n",
    "\n",
    "X = torch.tensor([-10.0])\n",
    "my_model = nn.Sequential(nn.Linear(1, 1),nn.Sigmoid())\n",
    "yhat = my_model(X)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- \n",
    "my_model = nn.Sequential(nn.Linear(1, 1),nn.Sigmoid())\n",
    "yhat = my_model(X)\n",
    "print(\"The prediction: \", yhat)\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_bottom\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/notebook_bottom%20.png\" width=\"750\" alt=\"PyTorch Bottom\" />\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n",
    "\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                          |\n",
    "| ----------------- | ------- | ---------- | ----------------------------------------------------------- |\n",
    "| 2020-09-23        | 2.0     | Shubham    | Migrated Lab to Markdown and added to course repo in GitLab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
